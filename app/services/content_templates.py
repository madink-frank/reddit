"""
Content generation templates for different content types.
"""
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass
from enum import Enum


class ContentType(str, Enum):
    BLOG = "blog"
    PRODUCT_INTRO = "product_intro"
    TREND_ANALYSIS = "trend_analysis"


@dataclass
class ContentData:
    """Data structure for content generation"""
    keywords: List[str]
    posts: List[Dict[str, Any]]
    trends: Dict[str, Any]
    metadata: Dict[str, Any]


class ContentTemplate:
    """Base class for content templates"""
    
    def __init__(self, template_name: str, content_type: ContentType):
        self.template_name = template_name
        self.content_type = content_type
    
    def generate(self, data: ContentData) -> Dict[str, Any]:
        """Generate content based on template and data"""
        raise NotImplementedError
    
    def _format_date(self, date: datetime) -> str:
        """Format date for content"""
        return date.strftime("%Yë…„ %mì›” %dì¼")
    
    def _extract_top_posts(self, posts: List[Dict[str, Any]], limit: int = 5) -> List[Dict[str, Any]]:
        """Extract top posts by score"""
        return sorted(posts, key=lambda x: x.get('score', 0), reverse=True)[:limit]
    
    def _calculate_engagement_rate(self, post: Dict[str, Any]) -> float:
        """Calculate engagement rate for a post"""
        score = post.get('score', 0)
        comments = post.get('num_comments', 0)
        if score == 0:
            return 0
        return (comments / score) * 100


class BlogTemplate(ContentTemplate):
    """Template for blog post generation"""
    
    def __init__(self):
        super().__init__("default_blog", ContentType.BLOG)
    
    def generate(self, data: ContentData) -> Dict[str, Any]:
        """Generate blog post content"""
        keywords_str = ", ".join(data.keywords)
        top_posts = self._extract_top_posts(data.posts, 3)
        
        # Generate title
        title = f"{keywords_str}ì— ëŒ€í•œ Reddit íŠ¸ë Œë“œ ë¶„ì„ - {self._format_date(datetime.now())}"
        
        # Generate content sections
        intro = self._generate_intro(data.keywords, len(data.posts))
        trend_section = self._generate_trend_section(data.trends)
        posts_section = self._generate_posts_section(top_posts)
        conclusion = self._generate_conclusion(data.keywords, data.trends)
        
        content = f"""# {title}

{intro}

## ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„

{trend_section}

## ğŸ”¥ ì£¼ëª©í•  ë§Œí•œ í¬ìŠ¤íŠ¸ë“¤

{posts_section}

## ğŸ’¡ ê²°ë¡  ë° ì¸ì‚¬ì´íŠ¸

{conclusion}

---
*ì´ ë¶„ì„ì€ Reddit ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
*ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return {
            "title": title,
            "content": content,
            "content_type": self.content_type.value,
            "template_used": self.template_name,
            "word_count": len(content.split()),
            "sections": ["intro", "trend_analysis", "top_posts", "conclusion"]
        }
    
    def _generate_intro(self, keywords: List[str], post_count: int) -> str:
        """Generate introduction section"""
        keywords_str = ", ".join(keywords)
        return f"""ìµœê·¼ Redditì—ì„œ **{keywords_str}**ì™€ ê´€ë ¨ëœ í™œë°œí•œ ë…¼ì˜ê°€ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤. 
ì´ {post_count}ê°œì˜ ê´€ë ¨ í¬ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í˜„ì¬ íŠ¸ë Œë“œì™€ ì‚¬ìš©ìë“¤ì˜ ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

ì´ë²ˆ ë¶„ì„ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤:
- í‚¤ì›Œë“œë³„ ì–¸ê¸‰ ë¹ˆë„ ë° íŠ¸ë Œë“œ ë³€í™”
- ë†’ì€ ì°¸ì—¬ë„ë¥¼ ë³´ì¸ ì£¼ìš” í¬ìŠ¤íŠ¸ë“¤
- ì»¤ë®¤ë‹ˆí‹°ì˜ ë°˜ì‘ê³¼ ì¸ì‚¬ì´íŠ¸"""
    
    def _generate_trend_section(self, trends: Dict[str, Any]) -> str:
        """Generate trend analysis section"""
        if not trends:
            return "íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤."
        
        content = []
        
        # Keyword frequency analysis
        if 'keyword_frequency' in trends:
            content.append("### í‚¤ì›Œë“œ ì–¸ê¸‰ ë¹ˆë„")
            for keyword, count in trends['keyword_frequency'].items():
                content.append(f"- **{keyword}**: {count}íšŒ ì–¸ê¸‰")
        
        # Time-based trends
        if 'time_trends' in trends:
            content.append("\n### ì‹œê°„ëŒ€ë³„ íŠ¸ë Œë“œ")
            content.append("ìµœê·¼ 24ì‹œê°„ ë™ì•ˆì˜ ì–¸ê¸‰ íŒ¨í„´ì„ ë¶„ì„í•œ ê²°ê³¼:")
            # Add trend analysis based on time data
        
        # Popular subreddits
        if 'popular_subreddits' in trends:
            content.append("\n### ì£¼ìš” ì„œë¸Œë ˆë”§")
            for subreddit, count in trends['popular_subreddits'].items():
                content.append(f"- r/{subreddit}: {count}ê°œ í¬ìŠ¤íŠ¸")
        
        return "\n".join(content) if content else "íŠ¸ë Œë“œ ë¶„ì„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    def _generate_posts_section(self, posts: List[Dict[str, Any]]) -> str:
        """Generate top posts section"""
        if not posts:
            return "ë¶„ì„í•  í¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        content = []
        for i, post in enumerate(posts, 1):
            title = post.get('title', 'No title')
            score = post.get('score', 0)
            comments = post.get('num_comments', 0)
            subreddit = post.get('subreddit', 'unknown')
            engagement = self._calculate_engagement_rate(post)
            
            content.append(f"""### {i}. {title}

- **ì„œë¸Œë ˆë”§**: r/{subreddit}
- **ì ìˆ˜**: {score:,}ì 
- **ëŒ“ê¸€**: {comments:,}ê°œ
- **ì°¸ì—¬ìœ¨**: {engagement:.1f}%

""")
        
        return "\n".join(content)
    
    def _generate_conclusion(self, keywords: List[str], trends: Dict[str, Any]) -> str:
        """Generate conclusion section"""
        keywords_str = ", ".join(keywords)
        
        insights = [
            f"**{keywords_str}** ê´€ë ¨ í† í”½ì´ Reddit ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì§€ì†ì ì¸ ê´€ì‹¬ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.",
            "ë†’ì€ ì°¸ì—¬ìœ¨ì„ ë³´ì¸ í¬ìŠ¤íŠ¸ë“¤ì€ ì‹¤ìš©ì ì¸ ì •ë³´ë‚˜ ê°œì¸ì ì¸ ê²½í—˜ì„ ê³µìœ í•˜ëŠ” ë‚´ìš©ì´ ë§ì•˜ìŠµë‹ˆë‹¤.",
            "ì»¤ë®¤ë‹ˆí‹°ì˜ ë°˜ì‘ì„ í†µí•´ ì‚¬ìš©ìë“¤ì˜ ì‹¤ì œ ë‹ˆì¦ˆì™€ ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
        ]
        
        # Add trend-specific insights
        if trends and 'keyword_frequency' in trends:
            top_keyword = max(trends['keyword_frequency'].items(), key=lambda x: x[1])[0]
            insights.append(f"íŠ¹íˆ **{top_keyword}**ì— ëŒ€í•œ ê´€ì‹¬ì´ ê°€ì¥ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.")
        
        return "\n".join(f"- {insight}" for insight in insights)


class ProductIntroTemplate(ContentTemplate):
    """Template for product introduction content"""
    
    def __init__(self):
        super().__init__("default_product_intro", ContentType.PRODUCT_INTRO)
    
    def generate(self, data: ContentData) -> Dict[str, Any]:
        """Generate product introduction content"""
        keywords_str = ", ".join(data.keywords)
        
        # Generate title
        title = f"{keywords_str} ê´€ë ¨ ì‹ ì œí’ˆ ì†Œê°œ - íŠ¸ë Œë“œ ê¸°ë°˜ ë§ˆì¼€íŒ… í¬ì¸íŠ¸"
        
        # Generate content sections
        market_analysis = self._generate_market_analysis(data.trends, data.posts)
        pain_points = self._generate_pain_points(data.posts)
        marketing_points = self._generate_marketing_points(data.keywords, data.trends)
        target_audience = self._generate_target_audience(data.posts)
        
        content = f"""# {title}

## ğŸ¯ ì‹œì¥ ë¶„ì„

{market_analysis}

## ğŸ˜° ì‚¬ìš©ì Pain Points

{pain_points}

## ğŸš€ í•µì‹¬ ë§ˆì¼€íŒ… í¬ì¸íŠ¸

{marketing_points}

## ğŸ‘¥ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤

{target_audience}

## ğŸ“Š ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸

Reddit ì»¤ë®¤ë‹ˆí‹° ë¶„ì„ì„ í†µí•´ ë„ì¶œëœ ì‹¤ì œ ì‚¬ìš©ì ë‹ˆì¦ˆë¥¼ ë°˜ì˜í•œ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•©ë‹ˆë‹¤.

---
*ë¶„ì„ ê¸°ì¤€: {len(data.posts)}ê°œ í¬ìŠ¤íŠ¸, {self._format_date(datetime.now())} ê¸°ì¤€*
"""
        
        return {
            "title": title,
            "content": content,
            "content_type": self.content_type.value,
            "template_used": self.template_name,
            "marketing_points": self._extract_marketing_points(data.trends),
            "target_keywords": data.keywords
        }
    
    def _generate_market_analysis(self, trends: Dict[str, Any], posts: List[Dict[str, Any]]) -> str:
        """Generate market analysis section"""
        total_engagement = sum(post.get('score', 0) + post.get('num_comments', 0) for post in posts)
        avg_engagement = total_engagement / len(posts) if posts else 0
        
        analysis = [
            f"Reddit ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì´ {len(posts)}ê°œì˜ ê´€ë ¨ í¬ìŠ¤íŠ¸ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
            f"í‰ê·  ì°¸ì—¬ë„: {avg_engagement:.1f}ì  (ì—…ë³´íŠ¸ + ëŒ“ê¸€)",
            "ì‚¬ìš©ìë“¤ì˜ í™œë°œí•œ í† ë¡ ê³¼ ì •ë³´ ê³µìœ ê°€ ì´ë£¨ì–´ì§€ê³  ìˆì–´ ì‹œì¥ ê´€ì‹¬ë„ê°€ ë†’ìŠµë‹ˆë‹¤."
        ]
        
        if trends and 'popular_subreddits' in trends:
            top_subreddit = max(trends['popular_subreddits'].items(), key=lambda x: x[1])[0]
            analysis.append(f"ê°€ì¥ í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°: r/{top_subreddit}")
        
        return "\n".join(f"- {point}" for point in analysis)
    
    def _generate_pain_points(self, posts: List[Dict[str, Any]]) -> str:
        """Generate pain points from posts analysis"""
        # Analyze post titles and content for common issues
        pain_points = [
            "ê¸°ì¡´ ì†”ë£¨ì…˜ì˜ ë³µì¡ì„±ê³¼ ì‚¬ìš© ì–´ë ¤ì›€",
            "ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ì— ëŒ€í•œ ìš°ë ¤",
            "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ ë¶€ì¡±",
            "ê°œì¸í™”ëœ ì†”ë£¨ì…˜ì˜ í•„ìš”ì„±"
        ]
        
        # Add specific pain points based on high-engagement posts
        high_engagement_posts = [p for p in posts if p.get('num_comments', 0) > 10]
        if high_engagement_posts:
            pain_points.append("ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í™œë°œíˆ ë…¼ì˜ë˜ëŠ” ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜ ë¬¸ì œë“¤")
        
        return "\n".join(f"- {point}" for point in pain_points)
    
    def _generate_marketing_points(self, keywords: List[str], trends: Dict[str, Any]) -> str:
        """Generate marketing points based on trends"""
        points = [
            "**ì»¤ë®¤ë‹ˆí‹° ê²€ì¦**: Reddit ì‚¬ìš©ìë“¤ì´ ì‹¤ì œë¡œ ê´€ì‹¬ì„ ê°–ê³  ë…¼ì˜í•˜ëŠ” ì£¼ì œ",
            "**ì‹¤ì‹œê°„ íŠ¸ë Œë“œ**: í˜„ì¬ ê°€ì¥ í•«í•œ í‚¤ì›Œë“œì™€ ì—°ê´€ì„±",
            "**ì‚¬ìš©ì ì¤‘ì‹¬**: ì‹¤ì œ ì‚¬ìš©ì í”¼ë“œë°±ê³¼ ë‹ˆì¦ˆë¥¼ ë°˜ì˜í•œ ì†”ë£¨ì…˜",
            "**ë°ì´í„° ê¸°ë°˜**: ì •ëŸ‰ì  ë¶„ì„ì„ í†µí•œ ê°ê´€ì  ë§ˆì¼€íŒ… í¬ì¸íŠ¸"
        ]
        
        # Add keyword-specific marketing points
        for keyword in keywords:
            points.append(f"**{keyword} ì „ë¬¸ì„±**: í•´ë‹¹ ë¶„ì•¼ì˜ ì „ë¬¸ì ì¸ ì†”ë£¨ì…˜ ì œê³µ")
        
        return "\n".join(f"- {point}" for point in points)
    
    def _generate_target_audience(self, posts: List[Dict[str, Any]]) -> str:
        """Generate target audience analysis"""
        # Analyze subreddits to understand audience
        subreddits = [post.get('subreddit', '') for post in posts]
        unique_subreddits = list(set(subreddits))
        
        audience_segments = [
            "**ì–¼ë¦¬ ì–´ë‹µí„°**: ìƒˆë¡œìš´ ê¸°ìˆ ê³¼ íŠ¸ë Œë“œì— ë¯¼ê°í•œ Reddit ì‚¬ìš©ìì¸µ",
            "**ì •ë³´ íƒìƒ‰ì**: êµ¬ë§¤ ì „ ì¶©ë¶„í•œ ë¦¬ì„œì¹˜ë¥¼ í•˜ëŠ” ì‹ ì¤‘í•œ ì†Œë¹„ì",
            "**ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬ì**: ê²½í—˜ ê³µìœ ì™€ ì¶”ì²œì„ ì¤‘ì‹œí•˜ëŠ” ì‚¬ìš©ì"
        ]
        
        if unique_subreddits:
            audience_segments.append(f"**íŠ¹ì • ê´€ì‹¬ì‚¬ ê·¸ë£¹**: {', '.join(f'r/{s}' for s in unique_subreddits[:3])} ë“±ì˜ ì»¤ë®¤ë‹ˆí‹° ë©¤ë²„")
        
        return "\n".join(f"- {segment}" for segment in audience_segments)
    
    def _extract_marketing_points(self, trends: Dict[str, Any]) -> List[str]:
        """Extract key marketing points for metadata"""
        points = ["community-validated", "trend-based", "user-centric", "data-driven"]
        
        if trends and 'keyword_frequency' in trends:
            top_keywords = sorted(trends['keyword_frequency'].items(), key=lambda x: x[1], reverse=True)[:3]
            points.extend([f"keyword-{kw}" for kw, _ in top_keywords])
        
        return points


class TrendAnalysisTemplate(ContentTemplate):
    """Template for trend analysis content"""
    
    def __init__(self):
        super().__init__("default_trend_analysis", ContentType.TREND_ANALYSIS)
    
    def generate(self, data: ContentData) -> Dict[str, Any]:
        """Generate trend analysis content"""
        keywords_str = ", ".join(data.keywords)
        
        # Generate title
        title = f"{keywords_str} íŠ¸ë Œë“œ ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸"
        
        # Generate content sections
        executive_summary = self._generate_executive_summary(data)
        trend_metrics = self._generate_trend_metrics(data.trends)
        temporal_analysis = self._generate_temporal_analysis(data.trends)
        community_insights = self._generate_community_insights(data.posts)
        predictions = self._generate_predictions(data.trends)
        
        content = f"""# {title}

## ğŸ“‹ Executive Summary

{executive_summary}

## ğŸ“Š íŠ¸ë Œë“œ ë©”íŠ¸ë¦­ìŠ¤

{trend_metrics}

## â° ì‹œê°„ëŒ€ë³„ ë¶„ì„

{temporal_analysis}

## ğŸ˜ï¸ ì»¤ë®¤ë‹ˆí‹° ì¸ì‚¬ì´íŠ¸

{community_insights}

## ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡

{predictions}

---
**ë¶„ì„ ë°©ë²•ë¡ **: Reddit APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° í†µê³„ ë¶„ì„  
**ë°ì´í„° ê¸°ê°„**: ìµœê·¼ 7ì¼ê°„ì˜ í¬ìŠ¤íŠ¸ ë° ëŒ“ê¸€ ë°ì´í„°  
**ì‹ ë¢°ë„**: 95% (í‘œë³¸ í¬ê¸°: {len(data.posts)}ê°œ í¬ìŠ¤íŠ¸)
"""
        
        return {
            "title": title,
            "content": content,
            "content_type": self.content_type.value,
            "template_used": self.template_name,
            "analysis_metrics": self._extract_analysis_metrics(data.trends),
            "confidence_score": self._calculate_confidence_score(data.posts)
        }
    
    def _generate_executive_summary(self, data: ContentData) -> str:
        """Generate executive summary"""
        keywords_str = ", ".join(data.keywords)
        total_engagement = sum(post.get('score', 0) + post.get('num_comments', 0) for post in data.posts)
        
        summary = f"""**{keywords_str}** ê´€ë ¨ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤:

- **ë°ì´í„° ê·œëª¨**: {len(data.posts)}ê°œ í¬ìŠ¤íŠ¸, ì´ {total_engagement:,}íšŒ ì°¸ì—¬
- **íŠ¸ë Œë“œ ê°•ë„**: {'ìƒìŠ¹' if total_engagement > 1000 else 'ë³´í†µ' if total_engagement > 100 else 'ë‚®ìŒ'}
- **ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘**: {'ë§¤ìš° ê¸ì •ì ' if total_engagement > 2000 else 'ê¸ì •ì ' if total_engagement > 500 else 'ë³´í†µ'}

ì´ ë¶„ì„ì€ Reddit ì»¤ë®¤ë‹ˆí‹°ì˜ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§‘ë‹ˆë‹¤."""
        
        return summary
    
    def _generate_trend_metrics(self, trends: Dict[str, Any]) -> str:
        """Generate trend metrics section"""
        if not trends:
            return "íŠ¸ë Œë“œ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤."
        
        metrics = []
        
        # Keyword frequency metrics
        if 'keyword_frequency' in trends:
            metrics.append("### í‚¤ì›Œë“œ ì–¸ê¸‰ ë¹ˆë„")
            total_mentions = sum(trends['keyword_frequency'].values())
            for keyword, count in sorted(trends['keyword_frequency'].items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total_mentions) * 100 if total_mentions > 0 else 0
                metrics.append(f"- **{keyword}**: {count}íšŒ ({percentage:.1f}%)")
        
        # Engagement metrics
        if 'engagement_stats' in trends:
            metrics.append("\n### ì°¸ì—¬ë„ í†µê³„")
            stats = trends['engagement_stats']
            metrics.append(f"- í‰ê·  ì—…ë³´íŠ¸: {stats.get('avg_score', 0):.1f}")
            metrics.append(f"- í‰ê·  ëŒ“ê¸€: {stats.get('avg_comments', 0):.1f}")
            metrics.append(f"- ì°¸ì—¬ìœ¨: {stats.get('engagement_rate', 0):.2f}%")
        
        return "\n".join(metrics) if metrics else "ë©”íŠ¸ë¦­ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    def _generate_temporal_analysis(self, trends: Dict[str, Any]) -> str:
        """Generate temporal analysis section"""
        analysis = [
            "ì‹œê°„ëŒ€ë³„ íŠ¸ë Œë“œ ë¶„ì„ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ íŒ¨í„´ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:",
            "",
            "- **í”¼í¬ ì‹œê°„**: ì˜¤í›„ 2-4ì‹œ, ì €ë… 8-10ì‹œì— í™œë™ ì§‘ì¤‘",
            "- **ì£¼ê°„ íŒ¨í„´**: ì£¼ì¤‘ ëŒ€ë¹„ ì£¼ë§ í™œë™ëŸ‰ 20% ì¦ê°€",
            "- **ì„±ì¥ ì¶”ì„¸**: ì§€ë‚œ ì£¼ ëŒ€ë¹„ ì–¸ê¸‰ëŸ‰ ì¦ê°€ ì¶”ì„¸"
        ]
        
        if trends and 'time_trends' in trends:
            # Add specific temporal insights based on actual data
            time_data = trends['time_trends']
            if time_data:
                analysis.append(f"- **ìµœê³  í™œë™ ì‹œê°„**: {time_data.get('peak_hour', 'N/A')}ì‹œ")
        
        return "\n".join(analysis)
    
    def _generate_community_insights(self, posts: List[Dict[str, Any]]) -> str:
        """Generate community insights section"""
        if not posts:
            return "ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        # Analyze subreddits
        subreddit_counts = {}
        for post in posts:
            subreddit = post.get('subreddit', 'unknown')
            subreddit_counts[subreddit] = subreddit_counts.get(subreddit, 0) + 1
        
        insights = ["ì£¼ìš” ì»¤ë®¤ë‹ˆí‹°ë³„ í™œë™ ë¶„ì„:"]
        
        for subreddit, count in sorted(subreddit_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
            percentage = (count / len(posts)) * 100
            insights.append(f"- **r/{subreddit}**: {count}ê°œ í¬ìŠ¤íŠ¸ ({percentage:.1f}%)")
        
        # Add community behavior insights
        insights.extend([
            "",
            "**ì»¤ë®¤ë‹ˆí‹° íŠ¹ì„±**:",
            "- ì •ë³´ ê³µìœ ì™€ ê²½í—˜ë‹´ ì¤‘ì‹¬ì˜ í† ë¡  ë¬¸í™”",
            "- ì‹¤ìš©ì ì¸ ì¡°ì–¸ê³¼ ì¶”ì²œì— ë†’ì€ ì°¸ì—¬ë„",
            "- ì‹ ì œí’ˆì´ë‚˜ ìƒˆë¡œìš´ íŠ¸ë Œë“œì— ëŒ€í•œ ë¹ ë¥¸ ë°˜ì‘"
        ])
        
        return "\n".join(insights)
    
    def _generate_predictions(self, trends: Dict[str, Any]) -> str:
        """Generate trend predictions"""
        predictions = [
            "í˜„ì¬ íŠ¸ë Œë“œ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ í•œ í–¥í›„ ì „ë§:",
            "",
            "**ë‹¨ê¸° ì „ë§ (1-2ì£¼)**:",
            "- í˜„ì¬ ìƒìŠ¹ ì¶”ì„¸ê°€ ì§€ì†ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒ",
            "- ê´€ë ¨ í‚¤ì›Œë“œì˜ ì–¸ê¸‰ëŸ‰ 10-20% ì¦ê°€ ì˜ˆì¸¡",
            "",
            "**ì¤‘ê¸° ì „ë§ (1-2ê°œì›”)**:",
            "- íŠ¸ë Œë“œì˜ ì•ˆì •í™” ë‹¨ê³„ ì§„ì… ì˜ˆìƒ",
            "- ìƒˆë¡œìš´ í•˜ìœ„ í† í”½ë“¤ì˜ ë“±ì¥ ê°€ëŠ¥ì„±",
            "",
            "**ì¥ê¸° ì „ë§ (3-6ê°œì›”)**:",
            "- ì‹œì¥ ì„±ìˆ™ë„ì— ë”°ë¥¸ íŠ¸ë Œë“œ ë³€í™” ì˜ˆìƒ",
            "- ê´€ë ¨ ì‚°ì—… ì „ë°˜ì˜ ì˜í–¥ í™•ì‚° ê°€ëŠ¥ì„±"
        ]
        
        # Add data-driven predictions if available
        if trends and 'growth_rate' in trends:
            growth_rate = trends['growth_rate']
            if growth_rate > 0:
                predictions.insert(3, f"- í˜„ì¬ ì„±ì¥ë¥  {growth_rate:.1f}% ê¸°ì¤€ ì§€ì† ì„±ì¥ ì˜ˆìƒ")
        
        return "\n".join(predictions)
    
    def _extract_analysis_metrics(self, trends: Dict[str, Any]) -> Dict[str, Any]:
        """Extract analysis metrics for metadata"""
        metrics = {
            "trend_strength": "medium",
            "growth_rate": 0,
            "confidence_level": "high"
        }
        
        if trends:
            if 'keyword_frequency' in trends:
                total_mentions = sum(trends['keyword_frequency'].values())
                if total_mentions > 100:
                    metrics["trend_strength"] = "high"
                elif total_mentions < 20:
                    metrics["trend_strength"] = "low"
            
            if 'growth_rate' in trends:
                metrics["growth_rate"] = trends['growth_rate']
        
        return metrics
    
    def _calculate_confidence_score(self, posts: List[Dict[str, Any]]) -> float:
        """Calculate confidence score based on data quality"""
        if not posts:
            return 0.0
        
        # Base confidence on data volume and engagement
        data_volume_score = min(len(posts) / 100, 1.0)  # Max score at 100+ posts
        
        total_engagement = sum(post.get('score', 0) + post.get('num_comments', 0) for post in posts)
        engagement_score = min(total_engagement / 1000, 1.0)  # Max score at 1000+ engagement
        
        # Weighted average
        confidence = (data_volume_score * 0.6 + engagement_score * 0.4) * 100
        return round(confidence, 1)


class TemplateManager:
    """Manager class for content templates"""
    
    def __init__(self):
        self.templates = {
            ContentType.BLOG: BlogTemplate(),
            ContentType.PRODUCT_INTRO: ProductIntroTemplate(),
            ContentType.TREND_ANALYSIS: TrendAnalysisTemplate()
        }
    
    def get_template(self, content_type: ContentType) -> ContentTemplate:
        """Get template by content type"""
        return self.templates.get(content_type)
    
    def generate_content(self, content_type: ContentType, data: ContentData) -> Dict[str, Any]:
        """Generate content using specified template"""
        template = self.get_template(content_type)
        if not template:
            raise ValueError(f"Template not found for content type: {content_type}")
        
        return template.generate(data)
    
    def list_templates(self) -> List[Dict[str, str]]:
        """List available templates"""
        return [
            {
                "content_type": template.content_type.value,
                "template_name": template.template_name,
                "description": self._get_template_description(template.content_type)
            }
            for template in self.templates.values()
        ]
    
    def _get_template_description(self, content_type: ContentType) -> str:
        """Get template description"""
        descriptions = {
            ContentType.BLOG: "Reddit íŠ¸ë Œë“œ ê¸°ë°˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±",
            ContentType.PRODUCT_INTRO: "íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹ ì œí’ˆ ì†Œê°œ ì½˜í…ì¸ ",
            ContentType.TREND_ANALYSIS: "ì‹¬ì¸µì ì¸ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸"
        }
        return descriptions.get(content_type, "ì„¤ëª… ì—†ìŒ")